{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_ai_with_fiddler_functions import *\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"OPENAI_API_KEY_PATH\": \"../keys/openai_key.txt\",\n",
    "        \"TRANSFORMERS_MODEL\": 'sentence-transformers/paraphrase-mpnet-base-v2',\n",
    "        \"SIMILARITY_THRESHOLD\": 0.75,\n",
    "        \"PRE_CONTEXT\": \"Answer the following question in a concise manner.\",\n",
    "        \"POST_CONTEXT\": \"Generate the response in JSON format with the key 'answer'.\",\n",
    "        \"models\": ['text-davinci-003', 'text-curie-001']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_API_KEY_PATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abiga\\OneDrive\\Documents\\PythonScripts\\fiddler_ai\\code\\fiddler_demo.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abiga/OneDrive/Documents/PythonScripts/fiddler_ai/code/fiddler_demo.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abiga/OneDrive/Documents/PythonScripts/fiddler_ai/code/fiddler_demo.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Initialize the models and set the API key\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abiga/OneDrive/Documents/PythonScripts/fiddler_ai/code/fiddler_demo.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m set_openai_api_key(config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abiga/OneDrive/Documents/PythonScripts/fiddler_ai/code/fiddler_demo.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m openai_llm \u001b[39m=\u001b[39m initialize_openai_llm(config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abiga/OneDrive/Documents/PythonScripts/fiddler_ai/code/fiddler_demo.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m similarity_model \u001b[39m=\u001b[39m initialize_similarity_model(config)\n",
      "File \u001b[1;32mc:\\Users\\abiga\\OneDrive\\Documents\\PythonScripts\\fiddler_ai\\code\\open_ai_with_fiddler_functions.py:17\u001b[0m, in \u001b[0;36mset_openai_api_key\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_openai_api_key\u001b[39m(config):\n\u001b[1;32m---> 17\u001b[0m     api_key \u001b[39m=\u001b[39m read_api_key(config[\u001b[39m\"\u001b[39;49m\u001b[39mOPENAI_API_KEY_PATH\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     18\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m api_key\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OPENAI_API_KEY_PATH'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Initialize the models and set the API key\n",
    "set_openai_api_key(config)\n",
    "openai_llm = initialize_openai_llm(config)\n",
    "similarity_model = initialize_similarity_model(config)\n",
    "similar_json_behavior = SimilarJSON(similarity_model, config)\n",
    "\n",
    "# Define a function to apply the evaluation to each row\n",
    "def apply_evaluation(row):\n",
    "    return evaluate_row(row, openai_llm, similar_json_behavior, PRE_CONTEXT, POST_CONTEXT)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file_path = Path('../data/prompt_target_answer_pairs.csv')\n",
    "df = pd.read_csv(csv_file_path).head(2)\n",
    "\n",
    "# Apply the evaluation function to each row and collect the results into a list\n",
    "all_results = df.apply(apply_evaluation, axis=1).tolist()\n",
    "\n",
    "# Now all_results is a list of evaluation results\n",
    "# Each element corresponds to the evaluation of one prompt/best_answer pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_prompt': 'What is the powerhouse of the cell?',\n",
       " 'pre_context': 'Answer the following question in a concise manner.',\n",
       " 'post_context': \"Generate the response in JSON format with key 'answer'.\",\n",
       " 'perturbed_prompts': ['What is the powerhouse of the cell?',\n",
       "  \"The cell's powerhouse is known as the mitochondria.\",\n",
       "  'The mitochondria is often referred to as the powerhouse of the cell.',\n",
       "  \"The cell's energy generator is called the mitochondria.\",\n",
       "  'The mitochondria serves as the powerhouse of the cell.',\n",
       "  'The powerhouse of the cell is the mitochondria.'],\n",
       " 'perturbed_generations': ['\\n\\n{\"answer\": \"The powerhouse of the cell is the mitochondria.\"}',\n",
       "  '\\n\\n{\"answer\":\"The cell\\'s powerhouse is known as the mitochondria.\"}',\n",
       "  '\\n\\n{\"answer\": \"The mitochondria is known as the powerhouse of the cell because it is the organelle responsible for producing the majority of the energy used by the cell.\"}',\n",
       "  '\\n\\n{\"answer\": \"The cell\\'s energy generator is called the mitochondria.\"}',\n",
       "  '\\n\\n{ \"answer\" : \"The mitochondria serves as the powerhouse of the cell.\" }',\n",
       "  '\\n\\n{\"answer\": \"The powerhouse of the cell is the mitochondria.\"}'],\n",
       " 'reference_generation': 'The mitochondria is the powerhouse of the cell.',\n",
       " 'generation_kwargs': {'Provider': 'openai',\n",
       "  'Temperature': 0.8801676204360285,\n",
       "  'Model Name': 'text-davinci-003'},\n",
       " 'result': [True, True, True, True, True, True],\n",
       " 'metric': [{'Similarity Score': 0.87},\n",
       "  {'Similarity Score': 0.87},\n",
       "  {'Similarity Score': 0.86},\n",
       "  {'Similarity Score': 0.82},\n",
       "  {'Similarity Score': 0.9},\n",
       "  {'Similarity Score': 0.87}],\n",
       " 'expected_behavior_desc': \"Model's generations for perturbations are greater than 0.75 similarity metric compared to the reference generation AND the answer is in JSON format with the key - answer\",\n",
       " 'evaluation_type': <LLMEvalType.correctness: 'Correctness'>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = aggregate_results(all_results)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
