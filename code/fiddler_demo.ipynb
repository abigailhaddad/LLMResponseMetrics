{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters up top\n",
    "OPENAI_MODEL = 'text-davinci-003'\n",
    "TRANSFORMERS_MODEL = 'sentence-transformers/paraphrase-mpnet-base-v2'\n",
    "SIMILARITY_THRESHOLD = 0.75\n",
    "NUMBER_OF_TRIES = 5\n",
    "PRE_CONTEXT = \"Answer the following question in a concise manner.\"\n",
    "POST_CONTEXT  = \"Generate the response in JSON format with key 'answer'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying Perturbations: 100%|██████████| 6/6 [00:03<00:00,  1.51it/s]\n",
      "Applying Perturbations: 100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Initialize the models and set the API key\n",
    "set_openai_api_key()\n",
    "openai_llm = initialize_openai_llm(OPENAI_MODEL)\n",
    "similarity_model = initialize_similarity_model(TRANSFORMERS_MODEL)\n",
    "similar_json_behavior = SimilarJSON(similarity_model, SIMILARITY_THRESHOLD)\n",
    "\n",
    "# Define a function to apply the evaluation to each row\n",
    "def apply_evaluation(row):\n",
    "    return evaluate_row(row, openai_llm, similar_json_behavior, PRE_CONTEXT, POST_CONTEXT)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file_path = Path('../data/prompt_target_answer_pairs.csv')\n",
    "df = pd.read_csv(csv_file_path).head(2)\n",
    "\n",
    "# Apply the evaluation function to each row and collect the results into a list\n",
    "all_results = df.apply(apply_evaluation, axis=1).tolist()\n",
    "\n",
    "# Now all_results is a list of evaluation results\n",
    "# Each element corresponds to the evaluation of one prompt/best_answer pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_prompt': 'What is the powerhouse of the cell?',\n",
       " 'pre_context': 'Answer the following question in a concise manner.',\n",
       " 'post_context': \"Generate the response in JSON format with key 'answer'.\",\n",
       " 'perturbed_prompts': ['What is the powerhouse of the cell?',\n",
       "  \"The cell's powerhouse is known as the mitochondria.\",\n",
       "  'The mitochondria is often referred to as the powerhouse of the cell.',\n",
       "  \"The cell's energy generator is called the mitochondria.\",\n",
       "  'The mitochondria serves as the powerhouse of the cell.',\n",
       "  'The powerhouse of the cell is the mitochondria.'],\n",
       " 'perturbed_generations': ['\\n\\n{\"answer\": \"The powerhouse of the cell is the mitochondria.\"}',\n",
       "  '\\n\\n{\"answer\":\"The cell\\'s powerhouse is known as the mitochondria.\"}',\n",
       "  '\\n\\n{\"answer\": \"The mitochondria is known as the powerhouse of the cell because it is the organelle responsible for producing the majority of the energy used by the cell.\"}',\n",
       "  '\\n\\n{\"answer\": \"The cell\\'s energy generator is called the mitochondria.\"}',\n",
       "  '\\n\\n{ \"answer\" : \"The mitochondria serves as the powerhouse of the cell.\" }',\n",
       "  '\\n\\n{\"answer\": \"The powerhouse of the cell is the mitochondria.\"}'],\n",
       " 'reference_generation': 'The mitochondria is the powerhouse of the cell.',\n",
       " 'generation_kwargs': {'Provider': 'openai',\n",
       "  'Temperature': 0.8801676204360285,\n",
       "  'Model Name': 'text-davinci-003'},\n",
       " 'result': [True, True, True, True, True, True],\n",
       " 'metric': [{'Similarity Score': 0.87},\n",
       "  {'Similarity Score': 0.87},\n",
       "  {'Similarity Score': 0.86},\n",
       "  {'Similarity Score': 0.82},\n",
       "  {'Similarity Score': 0.9},\n",
       "  {'Similarity Score': 0.87}],\n",
       " 'expected_behavior_desc': \"Model's generations for perturbations are greater than 0.75 similarity metric compared to the reference generation AND the answer is in JSON format with the key - answer\",\n",
       " 'evaluation_type': <LLMEvalType.correctness: 'Correctness'>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = aggregate_results(all_results)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
