{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of this is to demo the pipeline and analytics functionality of LLMResponseMetrics. Please see the readme for more information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *  # this is pulling functions from the function.py file in the code subfolder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import string\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the code for running the core pipeline functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 12:06:24,366 - INFO - Reading prompts from CSV file.\n",
      "2024-01-03 12:06:34,081 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:06:34,089 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:06:53,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:06:53,637 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:07:08,869 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:07:08,873 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:07:32,150 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:07:32,174 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:07:58,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:07:58,154 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:18,202 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:18,218 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:23,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:23,150 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:08:28,049 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:28,172 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:28,176 - INFO - Run 0, Model gpt-3.5-turbo-0301: Similarity - 0.8945112824440002, Keywords - 0.7142857142857143, LLM Rating - 0.9\n",
      "2024-01-03 12:08:34,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:34,818 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:08:37,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:37,988 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:37,989 - INFO - Run 1, Model gpt-3.5-turbo-0301: Similarity - 0.9172542095184326, Keywords - 0.5, LLM Rating - 0.9\n",
      "2024-01-03 12:08:37,990 - INFO - Scores for metric 'similarity_score' have not stabilized in the last 2 runs. Scores: [0.8945112824440002, 0.9172542095184326]\n",
      "2024-01-03 12:08:41,669 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:41,807 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:08:44,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:44,571 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:44,572 - INFO - Run 2, Model gpt-3.5-turbo-0301: Similarity - 0.8967796564102173, Keywords - 0.5714285714285714, LLM Rating - 0.9\n",
      "2024-01-03 12:08:44,573 - INFO - Scores have stabilized across all metrics.\n",
      "2024-01-03 12:08:44,574 - INFO - Stable scores achieved for prompt 'What is the powerhouse of the cell and how does it work?' after 3 runs. Moving to next prompt.\n",
      "2024-01-03 12:08:46,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:46,893 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:08:49,996 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:50,005 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:50,007 - INFO - Run 0, Model gpt-3.5-turbo-0301: Similarity - 0.9334062337875366, Keywords - 0.13333333333333333, LLM Rating - 0.8\n",
      "2024-01-03 12:08:52,880 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:52,887 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:08:55,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:55,130 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:08:55,132 - INFO - Run 1, Model gpt-3.5-turbo-0301: Similarity - 0.8149586319923401, Keywords - 0.26666666666666666, LLM Rating - 0.8\n",
      "2024-01-03 12:08:55,133 - INFO - Scores for metric 'keyword_score' have not stabilized in the last 2 runs. Scores: [0.13333333333333333, 0.26666666666666666]\n",
      "2024-01-03 12:08:58,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:08:58,054 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:00,441 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:00,446 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:00,447 - INFO - Run 2, Model gpt-3.5-turbo-0301: Similarity - 0.8158857226371765, Keywords - 0.3333333333333333, LLM Rating - 0.8\n",
      "2024-01-03 12:09:00,448 - INFO - Scores for metric 'keyword_score' have not stabilized in the last 2 runs. Scores: [0.26666666666666666, 0.3333333333333333]\n",
      "2024-01-03 12:09:06,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:06,832 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:11,328 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:11,351 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:11,353 - INFO - Run 0, Model gpt-3.5-turbo-0301: Similarity - 0.7724370360374451, Keywords - 0.46153846153846156, LLM Rating - 0.9\n",
      "2024-01-03 12:09:15,694 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:15,715 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:18,569 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:18,577 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:18,579 - INFO - Run 1, Model gpt-3.5-turbo-0301: Similarity - 0.8020812273025513, Keywords - 0.3076923076923077, LLM Rating - 0.9\n",
      "2024-01-03 12:09:18,580 - INFO - Scores for metric 'similarity_score' have not stabilized in the last 2 runs. Scores: [0.7724370360374451, 0.8020812273025513]\n",
      "2024-01-03 12:09:25,179 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:25,428 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:29,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:29,223 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:29,224 - INFO - Run 2, Model gpt-3.5-turbo-0301: Similarity - 0.8684219717979431, Keywords - 0.7692307692307693, LLM Rating - 1.0\n",
      "2024-01-03 12:09:29,225 - INFO - Scores for metric 'similarity_score' have not stabilized in the last 2 runs. Scores: [0.8020812273025513, 0.8684219717979431]\n",
      "2024-01-03 12:09:34,209 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:34,216 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:36,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:36,026 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:36,026 - INFO - Run 0, Model gpt-3.5-turbo-0301: Similarity - 0.49812546372413635, Keywords - 0.0, LLM Rating - 0.2\n",
      "2024-01-03 12:09:39,927 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:39,943 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:41,552 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:41,568 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:41,568 - INFO - Run 1, Model gpt-3.5-turbo-0301: Similarity - 0.4829706847667694, Keywords - 0.0, LLM Rating - 0.2\n",
      "2024-01-03 12:09:41,568 - INFO - Scores have stabilized across all metrics.\n",
      "2024-01-03 12:09:41,568 - INFO - Stable scores achieved for prompt 'Which organelle contains the cell's futurogenic material and how does it work?' after 2 runs. Moving to next prompt.\n",
      "2024-01-03 12:09:43,032 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:43,032 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:44,963 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:44,963 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:44,963 - INFO - Run 0, Model gpt-3.5-turbo-0301: Similarity - 0.6112534999847412, Keywords - 0.1111111111111111, LLM Rating - 0.0\n",
      "2024-01-03 12:09:46,266 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:46,266 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:47,893 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:47,908 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:47,908 - INFO - Run 1, Model gpt-3.5-turbo-0301: Similarity - 0.5845518708229065, Keywords - 0.1111111111111111, LLM Rating - 0.0\n",
      "2024-01-03 12:09:47,908 - INFO - Scores have stabilized across all metrics.\n",
      "2024-01-03 12:09:47,908 - INFO - Stable scores achieved for prompt 'What particle stabilizes the membrane of hover frogs and how?' after 2 runs. Moving to next prompt.\n",
      "2024-01-03 12:09:52,177 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:52,183 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:09:54,376 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:54,395 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:09:54,396 - INFO - Run 0, Model gpt-3.5-turbo-0301: Similarity - 0.8542252779006958, Keywords - 0.36363636363636365, LLM Rating - 0.6\n",
      "2024-01-03 12:09:59,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:09:59,889 - INFO - API call successful. Model: gpt-3.5-turbo-0301, Provider: OPENAI\n",
      "2024-01-03 12:10:02,438 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-01-03 12:10:02,438 - INFO - API call successful. Model: gpt-4, Provider: OPENAI\n",
      "2024-01-03 12:10:02,438 - INFO - Run 1, Model gpt-3.5-turbo-0301: Similarity - 0.747782289981842, Keywords - 0.18181818181818182, LLM Rating - 0.6\n",
      "2024-01-03 12:10:02,438 - INFO - Scores have stabilized across all metrics.\n",
      "2024-01-03 12:10:02,438 - INFO - Stable scores achieved for prompt 'How do astroflora perform photosynthesis in low light?' after 2 runs. Moving to next prompt.\n"
     ]
    }
   ],
   "source": [
    "models_dict = {\n",
    "    #'claude-2.1':  \"ANTHROPIC\", \n",
    "    'gpt-3.5-turbo-0301': \"OPENAI\"\n",
    "               }  # these are the models that you want to actually test\n",
    "csv_file_path = '../data/prompt_target_answer_pairs.csv' # set this filepath to the file that contains your question-answer pairs\n",
    "similarity_model_name = 'sentence-transformers/paraphrase-mpnet-base-v2' # this is what you use for analyzing semantic similarity\n",
    "temperature = \"variable\" # you can set this to a number between 0 and 1 if you don't want to vary temperature for the model responses\n",
    "is_file_path = True # you can set this to false if you want to input data directly instead of via a file\n",
    "llm_evaluation_model = ['gpt-4', \"OPENAI\"] # this is the model that will compare your target answer to the actual responses\n",
    "instructions = \"Please answer thoroughly: \"\n",
    "perturbation_model = ['gpt-4', \"OPENAI\"] # I recommend using a good model for perturbations otherwise it may generate the wrong number\n",
    "stability_threshold= 2 # this is the number of period that the maximum score will have to be stable across all evaluation criteria before each prompt will stop running\n",
    "max_runs= 3  # this is the maximum number of runs that each prompt will get run if the stability threshold is never met\n",
    "\n",
    "pipeline = LLMAnalysisPipeline(\n",
    "    input_data=csv_file_path, \n",
    "    models_dict=models_dict, \n",
    "    perturbation_model=perturbation_model, \n",
    "    llm_evaluation_model=llm_evaluation_model,\n",
    "    temperature = temperature,\n",
    "    max_runs= max_runs,\n",
    "    is_file_path = is_file_path,\n",
    "    similarity_model_name = similarity_model_name,\n",
    "    instructions = instructions,\n",
    "    stability_threshold = stability_threshold\n",
    "\n",
    ")\n",
    "\n",
    "# Run the pipeline\n",
    "df_responses = pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is what the response table looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>actual_prompt</th>\n",
       "      <th>run_number</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>response_embedding</th>\n",
       "      <th>keyword_score</th>\n",
       "      <th>llm_rating</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What is the powerhouse of the cell and how doe...</td>\n",
       "      <td>The powerhouse of the cell is referred to as t...</td>\n",
       "      <td>0.983085</td>\n",
       "      <td>What is the powerhouse of the cell and how doe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894511</td>\n",
       "      <td>[0.023045534268021584, -0.2238667607307434, 0....</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[mitochondrion, mitochondria, atp, adenosine t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What is the powerhouse of the cell and how doe...</td>\n",
       "      <td>The powerhouse of the cell is the mitochondria...</td>\n",
       "      <td>0.413742</td>\n",
       "      <td>What is the powerhouse of the cell and how doe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917254</td>\n",
       "      <td>[0.0028413068503141403, -0.1677742451429367, 0...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[mitochondrion, mitochondria, atp, adenosine t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What is the powerhouse of the cell and how doe...</td>\n",
       "      <td>Yes, the cell's power station is called the mi...</td>\n",
       "      <td>0.290401</td>\n",
       "      <td>- Can you describe the cell's power station an...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.896780</td>\n",
       "      <td>[-0.007078335154801607, -0.21583737432956696, ...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[mitochondrion, mitochondria, atp, adenosine t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What is the basic unit of life and what does t...</td>\n",
       "      <td>The basic unit of life is the cell. This means...</td>\n",
       "      <td>0.215484</td>\n",
       "      <td>What is the basic unit of life and what does t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933406</td>\n",
       "      <td>[0.01846599206328392, -0.30291128158569336, 0....</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[cell, biology, prokaryotic cells, eukaryotic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What is the basic unit of life and what does t...</td>\n",
       "      <td>The essential unit of life is the cell. Cells ...</td>\n",
       "      <td>0.405299</td>\n",
       "      <td>- What is the essential unit of life and what ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814959</td>\n",
       "      <td>[-0.03705814108252525, -0.2848859429359436, 0....</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[cell, biology, prokaryotic cells, eukaryotic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What is the basic unit of life and what does t...</td>\n",
       "      <td>As an AI language model, I can help you answer...</td>\n",
       "      <td>0.560118</td>\n",
       "      <td>- Can you identify the primary unit of life an...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.815886</td>\n",
       "      <td>[0.05861984193325043, -0.30094394087791443, 0....</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[cell, biology, prokaryotic cells, eukaryotic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What do genes consist of and how do they work?</td>\n",
       "      <td>The constituents of genes are DNA (deoxyribonu...</td>\n",
       "      <td>0.649924</td>\n",
       "      <td>- What are the constituents of genes and how d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.772437</td>\n",
       "      <td>[-0.06517020612955093, 0.046741340309381485, 0...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[genes, dna, deoxyribonucleic acid, nucleotide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What do genes consist of and how do they work?</td>\n",
       "      <td>Genes are segments of DNA that contain the ins...</td>\n",
       "      <td>0.424485</td>\n",
       "      <td>- What constitutes genes and how do they perfo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802081</td>\n",
       "      <td>[-0.11767256259918213, -0.059758543968200684, ...</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[genes, dna, deoxyribonucleic acid, nucleotide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What do genes consist of and how do they work?</td>\n",
       "      <td>Genes are segments of DNA (deoxyribonucleic ac...</td>\n",
       "      <td>0.325109</td>\n",
       "      <td>- What makes up genes and how do they function?</td>\n",
       "      <td>2</td>\n",
       "      <td>0.868422</td>\n",
       "      <td>[-0.032052263617515564, -0.003288829233497381,...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[genes, dna, deoxyribonucleic acid, nucleotide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>Which organelle contains the cell's futurogeni...</td>\n",
       "      <td>The organelle that contains the cell's future ...</td>\n",
       "      <td>0.848460</td>\n",
       "      <td>- Can you specify the organelle that contains ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498125</td>\n",
       "      <td>[-0.03843337297439575, 0.00022915206500329077,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[chronocytum, futurogenic material, temporal a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>Which organelle contains the cell's futurogeni...</td>\n",
       "      <td>The organelle that stores the genetic informat...</td>\n",
       "      <td>0.297562</td>\n",
       "      <td>- Can you name the organelle that stores the g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482971</td>\n",
       "      <td>[-0.0345514677464962, 0.07993671298027039, 0.0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[chronocytum, futurogenic material, temporal a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What particle stabilizes the membrane of hover...</td>\n",
       "      <td>As an AI language model, I cannot find any inf...</td>\n",
       "      <td>0.857431</td>\n",
       "      <td>- What is the particle that helps keep the mem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611253</td>\n",
       "      <td>[0.017946427688002586, -0.03625018149614334, -...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[levitonium, hover frogs, membrane stabilizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>What particle stabilizes the membrane of hover...</td>\n",
       "      <td>As an AI language model, I do not have any kno...</td>\n",
       "      <td>0.674784</td>\n",
       "      <td>- What is the specific particle that keeps the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584552</td>\n",
       "      <td>[-0.02457946166396141, 0.15033292770385742, -0...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[levitonium, hover frogs, membrane stabilizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>How do astroflora perform photosynthesis in lo...</td>\n",
       "      <td>Astroflora, also known as space plants, are pl...</td>\n",
       "      <td>0.412093</td>\n",
       "      <td>- In what way do astroflora perform photosynth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854225</td>\n",
       "      <td>[0.09692230820655823, -0.10442223399877548, -0...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[astroflora, photosynthesis, low light conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>How do astroflora perform photosynthesis in lo...</td>\n",
       "      <td>As an AI language model, I don't have personal...</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>- How do astroflora manage the process of phot...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747782</td>\n",
       "      <td>[-0.006795603781938553, -0.05883701890707016, ...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[astroflora, photosynthesis, low light conditi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model                                    original_prompt  \\\n",
       "0   gpt-3.5-turbo-0301  What is the powerhouse of the cell and how doe...   \n",
       "1   gpt-3.5-turbo-0301  What is the powerhouse of the cell and how doe...   \n",
       "2   gpt-3.5-turbo-0301  What is the powerhouse of the cell and how doe...   \n",
       "3   gpt-3.5-turbo-0301  What is the basic unit of life and what does t...   \n",
       "4   gpt-3.5-turbo-0301  What is the basic unit of life and what does t...   \n",
       "5   gpt-3.5-turbo-0301  What is the basic unit of life and what does t...   \n",
       "6   gpt-3.5-turbo-0301     What do genes consist of and how do they work?   \n",
       "7   gpt-3.5-turbo-0301     What do genes consist of and how do they work?   \n",
       "8   gpt-3.5-turbo-0301     What do genes consist of and how do they work?   \n",
       "9   gpt-3.5-turbo-0301  Which organelle contains the cell's futurogeni...   \n",
       "10  gpt-3.5-turbo-0301  Which organelle contains the cell's futurogeni...   \n",
       "11  gpt-3.5-turbo-0301  What particle stabilizes the membrane of hover...   \n",
       "12  gpt-3.5-turbo-0301  What particle stabilizes the membrane of hover...   \n",
       "13  gpt-3.5-turbo-0301  How do astroflora perform photosynthesis in lo...   \n",
       "14  gpt-3.5-turbo-0301  How do astroflora perform photosynthesis in lo...   \n",
       "\n",
       "                                             response  temperature  \\\n",
       "0   The powerhouse of the cell is referred to as t...     0.983085   \n",
       "1   The powerhouse of the cell is the mitochondria...     0.413742   \n",
       "2   Yes, the cell's power station is called the mi...     0.290401   \n",
       "3   The basic unit of life is the cell. This means...     0.215484   \n",
       "4   The essential unit of life is the cell. Cells ...     0.405299   \n",
       "5   As an AI language model, I can help you answer...     0.560118   \n",
       "6   The constituents of genes are DNA (deoxyribonu...     0.649924   \n",
       "7   Genes are segments of DNA that contain the ins...     0.424485   \n",
       "8   Genes are segments of DNA (deoxyribonucleic ac...     0.325109   \n",
       "9   The organelle that contains the cell's future ...     0.848460   \n",
       "10  The organelle that stores the genetic informat...     0.297562   \n",
       "11  As an AI language model, I cannot find any inf...     0.857431   \n",
       "12  As an AI language model, I do not have any kno...     0.674784   \n",
       "13  Astroflora, also known as space plants, are pl...     0.412093   \n",
       "14  As an AI language model, I don't have personal...     0.945170   \n",
       "\n",
       "                                        actual_prompt  run_number  \\\n",
       "0   What is the powerhouse of the cell and how doe...           0   \n",
       "1   What is the powerhouse of the cell and how doe...           1   \n",
       "2   - Can you describe the cell's power station an...           2   \n",
       "3   What is the basic unit of life and what does t...           0   \n",
       "4   - What is the essential unit of life and what ...           1   \n",
       "5   - Can you identify the primary unit of life an...           2   \n",
       "6   - What are the constituents of genes and how d...           0   \n",
       "7   - What constitutes genes and how do they perfo...           1   \n",
       "8     - What makes up genes and how do they function?           2   \n",
       "9   - Can you specify the organelle that contains ...           0   \n",
       "10  - Can you name the organelle that stores the g...           1   \n",
       "11  - What is the particle that helps keep the mem...           0   \n",
       "12  - What is the specific particle that keeps the...           1   \n",
       "13  - In what way do astroflora perform photosynth...           0   \n",
       "14  - How do astroflora manage the process of phot...           1   \n",
       "\n",
       "    similarity_score                                 response_embedding  \\\n",
       "0           0.894511  [0.023045534268021584, -0.2238667607307434, 0....   \n",
       "1           0.917254  [0.0028413068503141403, -0.1677742451429367, 0...   \n",
       "2           0.896780  [-0.007078335154801607, -0.21583737432956696, ...   \n",
       "3           0.933406  [0.01846599206328392, -0.30291128158569336, 0....   \n",
       "4           0.814959  [-0.03705814108252525, -0.2848859429359436, 0....   \n",
       "5           0.815886  [0.05861984193325043, -0.30094394087791443, 0....   \n",
       "6           0.772437  [-0.06517020612955093, 0.046741340309381485, 0...   \n",
       "7           0.802081  [-0.11767256259918213, -0.059758543968200684, ...   \n",
       "8           0.868422  [-0.032052263617515564, -0.003288829233497381,...   \n",
       "9           0.498125  [-0.03843337297439575, 0.00022915206500329077,...   \n",
       "10          0.482971  [-0.0345514677464962, 0.07993671298027039, 0.0...   \n",
       "11          0.611253  [0.017946427688002586, -0.03625018149614334, -...   \n",
       "12          0.584552  [-0.02457946166396141, 0.15033292770385742, -0...   \n",
       "13          0.854225  [0.09692230820655823, -0.10442223399877548, -0...   \n",
       "14          0.747782  [-0.006795603781938553, -0.05883701890707016, ...   \n",
       "\n",
       "    keyword_score  llm_rating  \\\n",
       "0        0.714286         0.9   \n",
       "1        0.500000         0.9   \n",
       "2        0.571429         0.9   \n",
       "3        0.133333         0.8   \n",
       "4        0.266667         0.8   \n",
       "5        0.333333         0.8   \n",
       "6        0.461538         0.9   \n",
       "7        0.307692         0.9   \n",
       "8        0.769231         1.0   \n",
       "9        0.000000         0.2   \n",
       "10       0.000000         0.2   \n",
       "11       0.111111         0.0   \n",
       "12       0.111111         0.0   \n",
       "13       0.363636         0.6   \n",
       "14       0.181818         0.6   \n",
       "\n",
       "                                             keywords  \n",
       "0   [mitochondrion, mitochondria, atp, adenosine t...  \n",
       "1   [mitochondrion, mitochondria, atp, adenosine t...  \n",
       "2   [mitochondrion, mitochondria, atp, adenosine t...  \n",
       "3   [cell, biology, prokaryotic cells, eukaryotic ...  \n",
       "4   [cell, biology, prokaryotic cells, eukaryotic ...  \n",
       "5   [cell, biology, prokaryotic cells, eukaryotic ...  \n",
       "6   [genes, dna, deoxyribonucleic acid, nucleotide...  \n",
       "7   [genes, dna, deoxyribonucleic acid, nucleotide...  \n",
       "8   [genes, dna, deoxyribonucleic acid, nucleotide...  \n",
       "9   [chronocytum, futurogenic material, temporal a...  \n",
       "10  [chronocytum, futurogenic material, temporal a...  \n",
       "11  [levitonium, hover frogs, membrane stabilizati...  \n",
       "12  [levitonium, hover frogs, membrane stabilizati...  \n",
       "13  [astroflora, photosynthesis, low light conditi...  \n",
       "14  [astroflora, photosynthesis, low light conditi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This shows how many times each prompt ran and which run produced the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_best_scores(df_responses):\n",
    "    methods = ['similarity_score', 'keyword_score', 'llm_rating']\n",
    "    \n",
    "    # Group by model, original prompt, and run number, then compute the max score for each method\n",
    "    max_scores = df_responses.groupby(['model', 'original_prompt', 'run_number'])[methods].max()\n",
    "\n",
    "    # Find the run number with the highest score for each method per prompt and model\n",
    "    best_runs = max_scores.groupby(level=[0, 1]).idxmax()\n",
    "\n",
    "    # Extract the run number and create a DataFrame\n",
    "    best_run_info = best_runs.map(lambda x: x[2] if pd.notna(x) else None)\n",
    "    best_run_info.columns = [f'best_run_{method}' for method in methods]\n",
    "\n",
    "    # Add total run count for each prompt and model\n",
    "    total_runs = df_responses.groupby(['model', 'original_prompt'])['run_number'].nunique()\n",
    "    best_run_info['total_runs'] = total_runs\n",
    "\n",
    "    best_run_info.reset_index(inplace=True)\n",
    "    best_run_info.rename(columns={'original_prompt': 'prompt'}, inplace=True)\n",
    "\n",
    "    return best_run_info\n",
    "\n",
    "df_best_scores = analyze_best_scores(df_responses)\n",
    "df_best_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This shows the best response for each prompt by similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_best_scores(df_responses, \"similarity_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This shows the best response for each prompt by keyword score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_best_scores(df_responses, 'keyword_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This shows the best response for each prompt by LLM rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_best_scores(df_responses, 'llm_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This shows the spread in terms of responses by prompt and method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spread(df_responses):\n",
    "    methods = ['similarity_score', 'keyword_score', 'llm_rating']\n",
    "    \n",
    "    # Group by model and original prompt\n",
    "    grouped = df_responses.groupby(['model', 'original_prompt'])\n",
    "\n",
    "    # Aggregate the data to find the max, min, and std for each method\n",
    "    agg_functions = {method: ['max', 'min'] for method in methods}\n",
    "    spread_df = grouped.agg(agg_functions).reset_index()\n",
    "\n",
    "    # Flatten MultiIndex columns\n",
    "    spread_df.columns = ['_'.join(col).strip() if col[1] else col[0] for col in spread_df.columns.values]\n",
    "\n",
    "    return spread_df\n",
    "\n",
    "calculate_spread(df_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Graph: Max Scores by Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cumulative_max_graph(df, eval_metrics):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Define color sequence\n",
    "    bold_colors = px.colors.qualitative.Bold\n",
    "    color_cycle = itertools.cycle(bold_colors)\n",
    "\n",
    "    # Calculate cumulative max for each metric\n",
    "    for metric in eval_metrics:\n",
    "        df_copy.loc[:, metric] = df_copy[metric].cummax()\n",
    "\n",
    "    # Create line graph\n",
    "    fig = go.Figure()\n",
    "    for metric in eval_metrics:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_copy['run_number'], \n",
    "            y=df_copy[metric], \n",
    "            mode='lines+markers', \n",
    "            name=metric,\n",
    "            line=dict(color=next(color_cycle))\n",
    "        ))\n",
    "\n",
    "    # Update graph layout for better aesthetics\n",
    "    fig.update_layout(\n",
    "        title='Cumulative Max Scores by Run Number',\n",
    "        xaxis_title='Run Number',\n",
    "        yaxis_title='Cumulative Max Score',\n",
    "        legend_title='Metrics',\n",
    "        plot_bgcolor='white',\n",
    "        xaxis=dict(showline=True, showgrid=False, linecolor='black'),\n",
    "        yaxis=dict(showline=True, showgrid=False, linecolor='black'),\n",
    "        font=dict(size=16),\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "first_prompt = df_responses.loc[df_responses['original_prompt']==df_responses['original_prompt'].iloc[10]]\n",
    "# List of evaluation metrics\n",
    "eval_metrics = ['similarity_score', 'keyword_score', 'llm_rating']\n",
    "\n",
    "# Create and show the plot\n",
    "create_cumulative_max_graph(first_prompt, eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
